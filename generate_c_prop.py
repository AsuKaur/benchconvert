# Property File Generator for Neural Network Verification

# This script generates C property files for neural network verification.
# It takes ONNX2C-generated C files and creates corresponding property files that
# can be used to verify specific properties of neural networks.

# The generated property files include:
# - Non-deterministic input generation
# - Input constraints (assumptions)
# - Calls to the neural network entry function
# - Assertions that determine SAT/UNSAT results based on filename patterns

# Usage:
#     python write_property_file.py model.c               # Generates prop_model.c
#     python write_property_file.py --all                 # Generates property files for all .c models
#     python write_property_file.py --all --onnx models/  # Use ONNX files for shape info


import argparse
import re
from pathlib import Path
import onnx

# Directory containing the C network files
C_NETWORK_DIR = Path("c_network")
C_PROP_DIR = Path("c_prop")

def extract_entry_signature(c_path):
    # Extract the entry() function signature from a C file.
    
    # This function parses the C file to find the entry point function and extracts
    # its parameter signature. The entry function is expected to be the main neural
    # network inference function generated by ONNX2C.
    
    # Args:
    #     c_path (Path): Path to the C file containing the neural network implementation
        
    # Returns:
    #     list: List of parameter declarations as strings (e.g., ["const float input[1][784]", "float output[1][10]"])
        
    # Raises:
    #     ValueError: If no entry function is found in the file
    
    #  Example:
    #     For a C file containing:
    #     void entry(const float input[1][784], float output[1][10]) { ... }
        
    #     Returns: ["const float input[1][784]", "float output[1][10]"] 

    content = c_path.read_text()
    # Use regex to find the entry function signature
    # Matches: void entry(...) followed by { or ;
    match = re.search(r'void\s+entry\s*\((.*?)\)\s*(?:\{|;)', content, re.DOTALL)
    if not match:
        raise ValueError(f"No entry function found in {c_path.name}")
    
    # Split parameters by comma and strip whitespace
    return [arg.strip() for arg in match.group(1).split(',')]

def parse_tensor_dec(decl):
    # Parse a tensor declaration string to extract name and dimensions.
    
    # This function parses C array declarations to extract the tensor name and its
    # dimensions. Currently supports 2D arrays (matrices) which are common in
    # neural network implementations.
    
    # Args:
    #     decl (str): C array declaration string (e.g., "const float input[1][784]")
        
    # Returns:
    #     tuple: (tensor_name, batch_size, feature_size)
        
    # Raises:
    #     ValueError: If the declaration format is not supported
        
    # Example:
    #     parse_tensor_dec("const float input[1][784]") 
    #     Returns: ("input", 1, 784)
    
    # Match pattern: [const] float name[dim1][dim2]
    match = re.match(r'(?:const\s+)?float\s+(\w+)\[(\d+)\]\[(\d+)\]', decl)
    if not match:
        raise ValueError(f"Unsupported tensor declaration: {decl}")
    
    tensor_name = match.group(1)
    dim1 = int(match.group(2))  # Usually batch size
    dim2 = int(match.group(3))  # Usually feature size
    
    return tensor_name, dim1, dim2

# def extract_io_shapes_from_onnx(onnx_path):
#     # Extract input and output tensor shapes from an ONNX model file.
    
#     # This function loads an ONNX model and extracts the shapes of the first
#     # input and output tensors. This is used as an alternative to parsing
#     # the C file signatures when ONNX files are available.
    
#     # Args:
#     #     onnx_path (Path): Path to the ONNX model file
        
#     # Returns:
#     #     tuple: ((input_name, input_shape), (output_name, output_shape))
        
#     # Example:
#     #     Returns: (("input", [1, 784]), ("output", [1, 10]))

#     # Load the ONNX model
#     model = onnx.load(onnx_path)
#     graph = model.graph

#     def get_shape(info):
#         """Extract shape from ONNX tensor info, defaulting unknown dims to 1."""
#         return [int(d.dim_value or 1) for d in info.type.tensor_type.shape.dim]

#     # Get first input and output tensors
#     input_tensor = graph.input[0]
#     output_tensor = graph.output[0]
    
#     return (input_tensor.name, get_shape(input_tensor)), (output_tensor.name, get_shape(output_tensor))

def determine_expected_result(filename):
    # Determine if a file should produce SAT or UNSAT based on filename patterns.
    
    # This function analyzes the filename to determine the expected verification result.
    # It uses common naming conventions to infer whether the property should be
    # satisfiable (SAT) or unsatisfiable (UNSAT).
    
    # Args:
    #     filename (str): The name of the C file
        
    # Returns:
    #     str: Either 'SAT' or 'UNSAT'
        
    # Naming conventions:
    #     - Files with "sat" (but not "unsat") -> SAT
    #     - Files with "unsat" -> UNSAT  
    #     - Files with "safe", "holds", "valid" -> SAT
    #     - Files with "unsafe", "violation", "invalid" -> UNSAT
    #     - Default -> SAT (with warning)
    
    filename_lower = filename.lower()
    
    # Check for explicit SAT/UNSAT markers in filename
    if 'sat' in filename_lower and 'unsat' not in filename_lower:
        return 'SAT'
    elif 'unsat' in filename_lower:
        return 'UNSAT'
    
    # Check for other common patterns that indicate expected results
    # These patterns are based on common verification benchmarking conventions
    if any(pattern in filename_lower for pattern in ['safe', 'holds', 'valid']):
        return 'SAT'
    elif any(pattern in filename_lower for pattern in ['unsafe', 'violation', 'invalid']):
        return 'UNSAT'
    
    # Default to SAT if no clear indication is found
    print(f"Warning: Could not determine expected result for {filename}, defaulting to SAT")
    return 'SAT'

def generate_property_code(input_name, input_shape, output_name, output_shape, expected_result):
    # Generate C code for a property file.
    
    # This function creates a complete C program that:
    # 1. Declares input and output tensors
    # 2. Initializes inputs with non-deterministic values
    # 3. Constrains inputs to valid ranges using assumptions
    # 4. Calls the neural network entry function
    # 5. Asserts properties based on expected result
    
    # Args:
    #     input_name (str): Name of the input tensor
    #     input_shape (tuple): Shape of input tensor (batch_size, features)
    #     output_name (str): Name of the output tensor  
    #     output_shape (tuple): Shape of output tensor (batch_size, classes)
    #     expected_result (str): Expected verification result ('SAT' or 'UNSAT')
        
    # Returns:
    #     str: Complete C code for the property file


    B, N = input_shape          # Batch size and input features
    B_out, M = output_shape     # Output batch size and output classes

    lines = []
    
    # Include verifier functions header
    lines.append('#include "verifier_functions.h"\n')
    
    # Forward declaration of the neural network entry function
    lines.append(f'void entry(const float {input_name}[{B}][{N}], float {output_name}[{B_out}][{M}]);\n')
    
    # Main function - entry point for verification
    lines.append('int main()\n{')
    
    # Declare input and output tensors
    lines.append(f'\tfloat {input_name}[{B}][{N}];')
    lines.append(f'\tfloat {output_name}[{B_out}][{M}];\n')

    # Initialize inputs with non-deterministic values
    for i in range(N):
        lines.append(f'\t{input_name}[0][{i}] = __VERIFIER_nondet_float();')
    lines.append('')
    
    # Add input constraints using assumptions
    for i in range(N):
        lines.append(f'\t__VERIFIER_assume({input_name}[0][{i}] >= 0.0f && {input_name}[0][{i}] <= 1.0f);')

    # Call the neural network entry function
    lines.append(f'\n\tentry({input_name}, {output_name});\n')
    
    # Generate assertion based on expected result
    if expected_result == 'SAT':
        # For SAT files: Create an assertion that should always hold
        # This assertion checks an impossible condition (output > 2.0 AND output < -1.0)
        # Since neural network outputs are typically in [0,1] range, this is always false
        # Therefore, the negation is always true, making the assertion always pass
        lines.append(f'\t// Expected result: SAT')
        lines.append(f'\t__VERIFIER_assert(!({output_name}[0][0] >= 1.0f && {output_name}[0][1] <= 0.0f));')
    else:  # UNSAT
        # For UNSAT files: Create an assertion that can be violated
        # This assertion requires both outputs to be negative (< 0.0)
        # Since neural network outputs are typically non-negative, this can be violated
        # When violated, the verifier will find a counterexample (UNSAT result)
        lines.append(f'\t// Expected result: UNSAT')
        lines.append(f'\t__VERIFIER_assert(!({output_name}[0][0] >= 1.0f || {output_name}[0][1] <= 0.0f));')
    
    # End main function
    lines.append('\n\treturn 0;\n}')
    
    return "\n".join(lines)

def write_property_file(c_file_path):
    # Generate a property file for a given C neural network file.
    
    # This function processes a single C file containing a neural network
    # implementation and generates a corresponding property file that can
    # be used for verification.
    
    # Args:
    #     c_file_path (Path): Path to the C file containing the neural network
        
    # The function:
    # 1. Determines expected result from filename
    # 2. Extracts tensor shapes (from C file)
    # 3. Generates property code
    # 4. Writes the property file

    try:
        # Determine expected verification result from filename patterns
        expected_result = determine_expected_result(c_file_path.name)

        # Extract shapes from C file function signature
        entry_args = extract_entry_signature(c_file_path)
        if len(entry_args) != 2:
            raise ValueError("Expected entry() to take two arguments.")
        
        # Parse input and output tensor declarations
        input_name, *in_dims = parse_tensor_dec(entry_args[0])
        output_name, *out_dims = parse_tensor_dec(entry_args[1])
        in_shape = tuple(in_dims)
        out_shape = tuple(out_dims)   

        # Generate the property verification code
        prop_code = generate_property_code(input_name, in_shape, output_name, out_shape, expected_result)
        
        # Write property file with "prop_" prefix
        prop_path = C_PROP_DIR / f"prop_{c_file_path.stem}.c"
        prop_path.write_text(prop_code)
        
        # Print success message with expected result
        print(f"✓ {prop_path.name} (Expected: {expected_result})")
        
    except Exception as e:
        # Print error message if processing fails
        print(f"✗ Failed for {c_file_path.name}: {e}")

def main():
    # Main function that handles command-line arguments and orchestrates the file generation.
    
    # This function:
    # 1. Parses command-line arguments
    # 2. Determines which files to process (single file or all files)
    # 3. Calls write_property_file() for each target file
    
    # Command-line options:
    # - Single file: python script.py model.c
    # - All files: python script.py --all

    # Set up argument parser
    parser = argparse.ArgumentParser(description="Generate property C files from onnx2c C files.")
    
    # Create mutually exclusive group for file selection
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("c_file", nargs="?", help="Single model C file in c_network/ (e.g., model.c)")
    group.add_argument("--all", action="store_true", help="Process all .c files in c_network/")
    
    args = parser.parse_args()

    if args.all:
        # Process all C files in the directory (original behavior)
        c_files = list(C_NETWORK_DIR.glob("*.c"))
        # Filter out existing property files (those starting with "prop_")
        model_files = [f for f in c_files if not f.name.startswith("prop_")]
        
        if not model_files:
            print("No model .c files found in c_network/")
            return
            
        print(f"Converting {len(model_files)} files...\n")

        # Create directories if they don't exist
        c_prop_dir = C_PROP_DIR
        c_prop_dir.mkdir(exist_ok=True)
        
        # Process each model file
        for c_file in model_files:
            write_property_file(c_file)
    else:
        # Process single specified file
        c_file = C_NETWORK_DIR / args.c_file
        
        if not c_file.exists():
            print(f"Error: {c_file} not found.")
            return
        
        # Create directories if they don't exist
        c_prop_dir = C_PROP_DIR
        c_prop_dir.mkdir(exist_ok=True)
            
        write_property_file(c_file)

if __name__ == "__main__":
    main()